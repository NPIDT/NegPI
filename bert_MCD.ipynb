{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model\n",
    "In this notebook, we format the data according to BERT's format.<br/>\n",
    "It is necessary to clone Google BERT's git repository, available at: https://github.com/google-research/bert.<br/>\n",
    "It is also needed to download the base BERT version : cased, 12-layer, 768-hidden, and 12-heads, 110M parameters, available at : https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_1-12.zip.\n",
    "The model folder should be inside the './bert_ba' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  label alpha                                           sentence\n",
      "0          0      1     a   McDonald 's is trash, in this case I mean lit...\n",
      "1          1      1     a  Here's What Eating Only  McDonald 's for 10 Da...\n",
      "2          2      1     a   mcdonald 's can most definitely be good rn ev...\n",
      "3          3      1     a  Nothing motivates my new diet than getting a p...\n",
      "4          4      1     a  How does this  McDonald 's not have any burger...\n",
      "5          5      0     a  Don't do any diettt, I just ate a  McDonald 's...\n",
      "6          6      1     a  Going on a 1 month  McDonald 's free diet chal...\n",
      "7          7      0     a  I just ate one fry from  McDonald 's cause I'm...\n",
      "8          8      0     a  *at the  mcdonald 's drive thru* hi yes can i ...\n",
      "9          9      1     a  I don't eat  McDonald 's, but they can go to h...\n",
      "10        10      0     a  christine: this is how you know what casey's d...\n",
      "11        11      0     a  wow. I wanted  McDonald 's McGriddles so bad s...\n",
      "12        12      1     a  Super Size Me(2004)documentary/Morgan personal...\n",
      "13        13      0     a     If I don't eat  McDonald 's today kilo Gafa   \n",
      "14        14      0     a  How are you going to take my order and then te...\n",
      "15        15      0     a  Pre season diet going really well this week.  ...\n",
      "16        16      0     a  I hate  McDonald 's but I'm craving it sm righ...\n",
      "17        17      0     a  Even if the data is solid, it's a stretch to s...\n",
      "18        18      0     a  Here's hoping he's back on his Ultra- McDonald...\n",
      "19        19      0     a    # lyle    mcdonald  ultimate diet 2 0     ht...\n",
      "20        20      1     a                               McDonald 's is trash\n",
      "21        21      1     a  my life is so meaningless when i take a bite o...\n",
      "22        22      1     a  I don't know y I really need to start my diet ...\n",
      "23        23      1     a  I get what I want ..., FOOOD all that cheap sh...\n",
      "24        24      0     a   McDonald 's is trash year round but really tr...\n",
      "25        25      0     a  What's great is that I puked up a $50 meal/dri...\n",
      "26        26      0     a  Here's a diet and health question?  If a girl ...\n",
      "27        27      1     a  Mann people stay offering me  McDonald 's and ...\n",
      "28        28      1     a  i will never eat  McDonald 's again, I threw t...\n",
      "29        29      1     a  I hate when I'm in the car with someone & they...\n",
      "...      ...    ...   ...                                                ...\n",
      "23072  23072      0     a  Starbucks and  McDonald 's plastic straw remov...\n",
      "23073  23073      0     a  Another one who when torn apart in an argument...\n",
      "23074  23074      0     a   McDonald 's stop it. it's 2am ffs I'm not all...\n",
      "23075  23075      0     a  Red M = Mario Yellow W = Wario Red W = Wieners...\n",
      "23076  23076      0     a  Damn! PJ was something serious too! But PJ did...\n",
      "23077  23077      0     a  Number of players ranked outside the Atp Top-1...\n",
      "23078  23078      0     a   MCDONALD 'S BALLARAT FNL FOOTY TV | Round 12 ...\n",
      "23079  23079      0     a  Who goes to  McDonald 's and thinks abt gtn a ...\n",
      "23080  23080      0     a  This parrot adds humour to every working day, ...\n",
      "23081  23081      0     a                            Mc Donald 's TE AMO    \n",
      "23082  23082      0     a  Donna  McDonald  7/10/18     https://www.  fac...\n",
      "23083  23083      0     a  at some point last night I ordered 40 chicken ...\n",
      "23084  23084      0     a                               Follow back, please!\n",
      "23085  23085      0     a  We were so blessed to have the opportunity to ...\n",
      "23086  23086      0     a  Off on a  McDonald 's run.        https://www....\n",
      "23087  23087      0     a  Time zones really fuck with your sleep   woke ...\n",
      "23088  23088      0     a                     How don't you understand them?\n",
      "23089  23089      0     a  These Pictures of the New  McDonald 's Headqua...\n",
      "23090  23090      0     a  Bidding War for  McDonald 's Monopoly Scam Set...\n",
      "23091  23091      0     a         Can someone bring me  McDonald 's please??\n",
      "23092  23092      0     a  Babylon bypass????? Even IBM Supercomputer fai...\n",
      "23093  23093      0     a  happy birthday to miss lainy!!! i mith you so ...\n",
      "23094  23094      0     a   McDonald 's Summerdays 2018: Chicken McNugget...\n",
      "23095  23095      0     a  Can't believe  McDonald 's has a code to get i...\n",
      "23096  23096      0     a  I'm at  McDonald 's & McCafe in Subang Jaya, S...\n",
      "23097  23097      0     a  Both of the  McDonald 's in Hays could win an ...\n",
      "23098  23098      0     a  Maintenance Person -  McDonald 's - Everett, W...\n",
      "23099  23099      0     a  Check out the 38 latest openings at Love's Tra...\n",
      "23100  23100      0     a  New on GT: Positives, Needs and Hopes.... Arse...\n",
      "23101  23101      0     a  You better BELIEVE I got myself fucking  McDon...\n",
      "\n",
      "[23102 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a5fd703d434f8588880ccab6146348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "2-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "3-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "4-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "5-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "6-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "7-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "8-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "9-th fold\n",
      "Splitting the data\n",
      "2309\n",
      "10-th fold\n",
      "Splitting the data\n",
      "2321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bert import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    " \n",
    "le = LabelEncoder()\n",
    " \n",
    "df = pd.read_csv('./labeled_mcd.csv', sep='\\t', index_col=0)\n",
    "df.index = list(range(df.shape[0]))\n",
    "y = list(df.pi)\n",
    "\n",
    "\"\"\"Formatting to BERT format\"\"\"\n",
    "df.rename(columns={'text':'sentence'}, inplace=True)\n",
    "df['alpha'] = pd.Series(['a'] * df.shape[0], index=df.index)\n",
    "df.rename(columns={'pi':'label'}, inplace=True)\n",
    "df['label'] = df.label.apply(int)\n",
    "df['id'] = pd.Series(list(range(df.shape[0])))\n",
    "df = df[['id','label','alpha','sentence']]\n",
    "\n",
    "print(df)\n",
    "\n",
    "\"\"\"Retrieving the positive and negative indexes\"\"\"\n",
    "neg_index = [k for k in range(len(y)) if y[k]==0]\n",
    "pos_index = [k for k in range(len(y)) if y[k]==1]\n",
    "\n",
    "\"\"\"Shuffling both the positive and negative indexes\"\"\"\n",
    "np.random.seed(seed=0)\n",
    "np.random.shuffle(neg_index)\n",
    "np.random.shuffle(pos_index)\n",
    "\n",
    "\"\"\"Computing train and test index sets for the chosen number of folds\"\"\"\n",
    "cv = 10\n",
    "\n",
    "s = len(neg_index)//cv\n",
    "neg_index_list = [neg_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "neg_index_list.append(neg_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in neg_index_list])==len(neg_index)) # Check on negative index completion\n",
    "\n",
    "s = len(pos_index)//cv\n",
    "pos_index_list = [pos_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "pos_index_list.append(pos_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in pos_index_list])==len(pos_index))# Check on positive index completion\n",
    "\n",
    "y_tests = []\n",
    "\n",
    "for k in tqdm(range(cv)):\n",
    "    \"\"\"Splitting the data into train and test\"\"\"\n",
    "    print('{}-th fold'.format(k+1))\n",
    "    print('Splitting the data')\n",
    "    neg_test = neg_index_list[k]\n",
    "    pos_test = pos_index_list[k]\n",
    "    neg_train = list(set(neg_index).difference(neg_index_list[k]))\n",
    "    pos_train = list(set(pos_index).difference(pos_index_list[k]))\n",
    "    \n",
    "    pos_dev = pos_train[-1:]\n",
    "    neg_dev = neg_train[-1:]\n",
    "    pos_train = pos_train[:-1]\n",
    "    neg_train = neg_train[:-1]\n",
    "    \n",
    "    \"\"\"Splitting the data frames and saving to BERT format\"\"\"\n",
    "    list_train = pos_train + neg_train\n",
    "    list_dev = pos_dev + neg_dev\n",
    "    list_test = pos_test + neg_test\n",
    "\n",
    "    np.random.shuffle(list_train)\n",
    "    np.random.shuffle(list_dev)\n",
    "    np.random.shuffle(list_test)\n",
    "    \n",
    "    train_df = df.iloc[list_train]\n",
    "    dev_df = df.iloc[list_dev]\n",
    "    test_df = df.iloc[list_test]\n",
    "    y_tests.append(list(test_df.label))\n",
    "    print(len(y_tests[-1]))\n",
    "    \n",
    "    \"\"\"Making the directory to save the data if it doesn't exist\"\"\"\n",
    "    if not os.path.exists('./bert_mcd/data_mcd_'+str(k+1)):\n",
    "        os.mkdir('./bert_mcd/data_mcd_'+str(k+1))\n",
    "    \n",
    "    train_df.to_csv('./bert_mcd/data_mcd_{}/train.tsv'.format(str(k+1)), sep='\\t', index=False, header=False)\n",
    "    dev_df.to_csv('./bert_mcd/data_mcd_{}/dev.tsv'.format(str(k+1)), sep='\\t', index=False, header=False)\n",
    "    test_df[['id','sentence']].to_csv('./bert_mcd/data_mcd_{}/test.tsv'.format(str(k+1)), sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f3eead8ce049b889dc18224b5f666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training and harvesting performance metrics\"\"\"\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "os.chdir(\"./bert_mcd\")\n",
    "precs = []\n",
    "recs = []\n",
    "fs = []\n",
    "aucs = []\n",
    "for k in tqdm(range(cv)):\n",
    "    \"\"\"Instruction to train, evaluate, and predict results on test data\"\"\"\n",
    "    os.system(\"python run_classifier.py --task_name=cola --do_train=true --do_eval=true --do-predict=true --data_dir=./data_mcd_{}/ --vocab_file=./cased_L-12_H-768_A-12/vocab.txt --bert_config_file=./cased_L-12_H-768_A-12/bert_config.json --init_checkpoint=./cased_L-12_H-768_A-12/bert_model.ckpt --max_seq_length=128 --train_batch_size=32 --learning_rate=2e-5 --num_train_epochs=10.0 --output_dir=./bert_output/ --do_lower_case=False\".format(str(k+1)))\n",
    "\n",
    "    test_res = pd.read_csv('./bert_output/test_results.tsv',sep='\\t', header=None)\n",
    "    test_res = list(test_res[1])\n",
    "    test_pred = [int(y>=0.5) for y in test_res]\n",
    "\n",
    "    y_test = y_tests[k]\n",
    "\n",
    "    precision = precision_score(y_test, test_pred)\n",
    "    recall = recall_score(y_test, test_pred)\n",
    "    f1_ = f1_score(y_test, test_pred)\n",
    "    roc_auc = roc_auc_score(y_test, test_res)\n",
    "    \n",
    "    precs.append(precision)\n",
    "    recs.append(recall)\n",
    "    fs.append(f1_)\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.5471863556185812+-\\0.05181507407202481\n",
      "Recall : 0.47018419693578933+-0.041914893879407514\n",
      "F1 score : 0.5048652334731056+-0.04163977921804463\n",
      "ROC AUC : 0.9683533494197031+-0.003961956519343309\n"
     ]
    }
   ],
   "source": [
    "print('Precision : {}+-\\{}\\nRecall : {}+-{}\\nF1 score : {}+-{}\\nROC AUC : {}+-{}'.format(np.mean(precs),np.std(precs),\n",
    "                                                                                         np.mean(recs),np.std(recs),\n",
    "                                                                                         np.mean(fs),np.std(fs),\n",
    "                                                                                         np.mean(aucs),np.std(aucs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
