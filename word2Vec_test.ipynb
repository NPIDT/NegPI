{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qrg-researchlab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/qrg-researchlab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/qrg-researchlab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/qrg-researchlab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/qrg-researchlab/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Word2Vec experiment\"\"\"\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\"\"\"Loading W2V matrix\"\"\"\n",
    "google_w2v = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading the data\"\"\"\n",
    "data = pickle.load(open('./label_tag_data.p', 'rb'))\n",
    "y = list(data.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ab874b6a9446dd83b6a1fe6790fcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11540), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Computing the average embedding of the tweets\"\"\"\n",
    "X = []\n",
    "for k in tqdm(range(data.shape[0])):\n",
    "    local = data.tag_df.iloc[k]\n",
    "    local = local[local.tag.isin(['A','R','N','V','@'])]\n",
    "    vectors = []\n",
    "    for word in list(local.word):\n",
    "        try:\n",
    "            vectors.append(google_w2v[word])\n",
    "        except:\n",
    "            pass\n",
    "    embedding = 0\n",
    "    if len(vectors)==0:\n",
    "        embedding = np.zeros(300)\n",
    "    else:\n",
    "        embedding = np.vstack([v.reshape((1,-1)) for v in vectors]).mean(axis=0)\n",
    "    X.append(list(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Balanced split for cross validation\"\"\"\n",
    "\n",
    "\"\"\"Retrieving the positive and negative indexes\"\"\"\n",
    "neg_index = [k for k in range(len(y)) if y[k]==0]\n",
    "pos_index = [k for k in range(len(y)) if y[k]==1]\n",
    "\n",
    "\"\"\"Shuffling both the positive and negative indexes\"\"\"\n",
    "np.random.seed(seed=0)\n",
    "np.random.shuffle(neg_index)\n",
    "np.random.shuffle(pos_index)\n",
    "\n",
    "\"\"\"Computing train and test index sets for the chosen number of folds\"\"\"\n",
    "cv = 10\n",
    "\n",
    "s = len(neg_index)//cv\n",
    "neg_index_list = [neg_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "neg_index_list.append(neg_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in neg_index_list])==len(neg_index)) # Check on negative index completion\n",
    "\n",
    "s = len(pos_index)//cv\n",
    "pos_index_list = [pos_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "pos_index_list.append(pos_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in pos_index_list])==len(pos_index))# Check on positive index completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "2-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "3-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "4-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "5-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "6-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "7-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "8-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "9-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "10-th fold\n",
      "Splitting the data\n",
      "Fitting the model\n",
      "Evaluation and storage of model parameters\n",
      "\n",
      "Averaged scores\n",
      "Average 10-fold F1 score : 0.39154198881607316\n",
      "Average 10-fold precision : 0.577692688337012\n",
      "Average 10-fold recall : 0.2977895164567249\n",
      "Average 10-fold ROC AUC : 0.8723757293978138\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Performing cross-validation for logistic regression on Word2Vec embedding representation\"\"\"\n",
    "\n",
    "\"\"\"Initializing the list of outputs, predictions and probabilities to computed CV-ly\"\"\"\n",
    "Y = []\n",
    "Y_Pred = []\n",
    "Y_Proba = []\n",
    "\n",
    "\"\"\"Intializing the list of cross-validated features\"\"\"\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "roc_auc_list = []\n",
    "f1_list = []\n",
    "\n",
    "\"\"\"Storing coefficients and biases for stability evaluation\"\"\"\n",
    "biases = []\n",
    "weights = []\n",
    "\n",
    "\"\"\"Performing the cross-validation of the model using the features of interest\n",
    "A caveat to be mentioned is that the feature selection was performed on the whole dataset, which may be a little biased towards choosing the right features.\n",
    "This effect will be neglected during this test.\"\"\"\n",
    "for k in range(cv):\n",
    "    \"\"\"Splitting the data into train and test\"\"\"\n",
    "    print('{}-th fold'.format(k+1))\n",
    "    print('Splitting the data')\n",
    "    neg_test = [X[i] for i in neg_index_list[k]]\n",
    "    pos_test = [X[i] for i in pos_index_list[k]]\n",
    "    neg_train = [X[i] for i in set(neg_index).difference(neg_index_list[k])]\n",
    "    pos_train = [X[i] for i in set(pos_index).difference(pos_index_list[k])]\n",
    "\n",
    "    X_train = pos_train + neg_train\n",
    "    X_test = pos_test + neg_test\n",
    "\n",
    "    y_train = [1] * len(pos_train) + [0] * len(neg_train)\n",
    "    y_test = [1] * len(pos_test) + [0] * len(neg_test)\n",
    "\n",
    "    \"\"\"Fitting the model\"\"\"\n",
    "    print('Fitting the model')\n",
    "    model = LogisticRegression(C=1e4)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Evaluation and storage of model parameters\\n')\n",
    "    \"\"\"Outputting the predictions and the probability scores\"\"\"\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \"\"\"Computing the various metrics\"\"\"\n",
    "    f1_list.append(f1_score(y_test, y_pred))\n",
    "    precision_list.append(precision_score(y_test, y_pred))\n",
    "    recall_list.append(recall_score(y_test, y_pred))\n",
    "    roc_auc_list.append(roc_auc_score(y_test, y_score))\n",
    "\n",
    "    \"\"\"Adding predictions and scores to computed global cross-validated performance after the end of the process\"\"\"\n",
    "    Y += list(y_test)\n",
    "    Y_Pred += list(y_pred)\n",
    "    Y_Proba += list(y_score)\n",
    "    \n",
    "\"\"\"Performance analysis for our model with 10-fold CV\"\"\"\n",
    "print('Averaged scores')\n",
    "print('Average {}-fold F1 score : {}'.format(cv, np.mean(f1_list)))\n",
    "print('Average {}-fold precision : {}'.format(cv, np.mean(precision_list)))\n",
    "print('Average {}-fold recall : {}'.format(cv, np.mean(recall_list)))\n",
    "print('Average {}-fold ROC AUC : {}'.format(cv, np.mean(roc_auc_list)))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
