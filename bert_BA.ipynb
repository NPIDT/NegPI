{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT model\n",
    "In this notebook, we format the data according to BERT's format.<br/>\n",
    "It is necessary to clone Google BERT's git repository, available at: https://github.com/google-research/bert.<br/>\n",
    "It is also needed to download the base BERT version : cased, 12-layer, 768-hidden, and 12-heads, 110M parameters, available at : https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_1-12.zip.\n",
    "The model folder should be inside the './bert_ba' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  label alpha                                           sentence\n",
      "0          0      0     a  \"Hi William, once again we're sorry you we're ...\n",
      "1          1      0     a  But!!!!! When we get to   @EdinburghAirpo1   t...\n",
      "2          2      0     a  \"That stuff about \"\"deportees on BA83\"\" seems ...\n",
      "3          3      0     a  Ok but how much longer can I expect to wait pl...\n",
      "4          4      0     a  I think they mean they won't cover the cost of...\n",
      "5          5      0     a  \"  @british_airways    App is currently faulty...\n",
      "6          6      0     a    @British_Airways    Can you explain why your...\n",
      "7          7      0     a  \"Hi Allyson, you can request a proof of travel...\n",
      "8          8      1     a  So what you are saying is that I can now forge...\n",
      "9          9      0     a  \"  @British_Airways    appalling service from ...\n",
      "10        10      0     a    @SushmaSwaraj   US Citizen stuck in India be...\n",
      "11        11      1     a  \"If you read the exchange you would see it was...\n",
      "12        12      0     a  No compensation or help from   @British_Airway...\n",
      "13        13      0     a  \"Sorry to hear you're not able to reset your p...\n",
      "14        14      0     a  Yes please.  So far  3 phone  calls and attemp...\n",
      "15        15      0     a  Haven't   @VirginAtlantic   pledged to stop as...\n",
      "16        16      1     a  \"It did as it happens. In addition we're still...\n",
      "17        17      0     a  Thanks for getting in contact. Upper and lower...\n",
      "18        18      0     a  Why do you want people who won't integrate in ...\n",
      "19        19      0     a  Just bought a coffee and   @British_Airways   ...\n",
      "20        20      0     a  Thanks   @British_Airways    but this doesn't ...\n",
      "21        21      0     a  Thanks. We were told 1 of the computers wont b...\n",
      "22        22      0     a  \"  @British_Airways    Hi, I'm supposed to be ...\n",
      "23        23      0     a  \"Unacceptable. Please do the right thing, BA. ...\n",
      "24        24      0     a  Supposed to but recently most airlines flying ...\n",
      "25        25      0     a  \"I am sorry that we won't be able to help you ...\n",
      "26        26      0     a  Why is it only skinny 8 year olds can get comf...\n",
      "27        27      0     a  \"  @british_airways    There is no way for me ...\n",
      "28        28      0     a  \"Hi there. Unfortunately, we won't be able to ...\n",
      "29        29      0     a    @British_Airways    how do I cancel a bookin...\n",
      "...      ...    ...   ...                                                ...\n",
      "11654  11654      0     a    @British_Airways    can you atleast respond ...\n",
      "11655  11655      0     a  \"'World's favorite airline' favorite among hac...\n",
      "11656  11656      0     a  Win this awesome   #Boeing     #B747   sweatsh...\n",
      "11657  11657      0     a   British Airways  apologizes after 380,000 cus...\n",
      "11658  11658      0     a  Ta. It's been like that for a week, I know tha...\n",
      "11659  11659      0     a  Throwing things? Like throwing an innocent ex ...\n",
      "11660  11660      0     a  Thanks to   @British_Airways    who are celebr...\n",
      "11661  11661      0     a  Sharing an oldie but a goodie! I hope you'll e...\n",
      "11662  11662      0     a  I used to design phones and now it's my job to...\n",
      "11663  11663      0     a  Business & Your Money: Airline Makes Business ...\n",
      "11664  11664      0     a    @British_Airways    second time in less than...\n",
      "11665  11665      0     a  Enjoyed the   @British_Airways    boarding cha...\n",
      "11666  11666      0     a  Shock, you're sitting on Twitter. Don't tell m...\n",
      "11667  11667      0     a  If I join in with Lara does that classify us a...\n",
      "11668  11668      0     a    #foodiefriday    British Airways  has confir...\n",
      "11669  11669      0     a   British Airways  to Suspend Flights Between L...\n",
      "11670  11670      0     a   British Airways  could face PS500m fine as re...\n",
      "11671  11671      0     a  I've flown with both and would definitely go w...\n",
      "11672  11672      0     a  That might be the case, Paul. But   @British_A...\n",
      "11673  11673      0     a  I changed time zones inbetween tweets so it ac...\n",
      "11674  11674      0     a  There is no brand left unfortunately, lost in ...\n",
      "11675  11675      0     a          Yeah, of course you do. And I'm the Pope.\n",
      "11676  11676      0     a                                     So many forms.\n",
      "11677  11677      0     a  Or even some other UK carriers. I doubt   @Vir...\n",
      "11678  11678      0     a    @British_Airways    36 days and counting wai...\n",
      "11679  11679      0     a    @British_Airways     British airways  have o...\n",
      "11680  11680      0     a  How Hackers Slipped by  British Airways ' Defe...\n",
      "11681  11681      0     a  I might get my passport tomorrow but it will b...\n",
      "11682  11682      0     a  So   @British_Airways    continue to drive for...\n",
      "11683  11683      0     a  Oh dear   @britishairways      #BA2667     #Ma...\n",
      "\n",
      "[11684 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76e6554ca1b49d0abfb899fe6f3293d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "2-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "3-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "4-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "5-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "6-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "7-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "8-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "9-th fold\n",
      "Splitting the data\n",
      "1167\n",
      "10-th fold\n",
      "Splitting the data\n",
      "1181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bert import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    " \n",
    "le = LabelEncoder()\n",
    " \n",
    "df = pd.read_csv('./labeled_ba.csv', sep='\\t', index_col=0)\n",
    "df.index = list(range(df.shape[0]))\n",
    "y = list(df.pi)\n",
    "\n",
    "\"\"\"Formatting to BERT format\"\"\"\n",
    "df.rename(columns={'text':'sentence'}, inplace=True)\n",
    "df['alpha'] = pd.Series(['a'] * df.shape[0], index=df.index)\n",
    "df.rename(columns={'pi':'label'}, inplace=True)\n",
    "df['label'] = df.label.apply(int)\n",
    "df['id'] = pd.Series(list(range(df.shape[0])))\n",
    "df = df[['id','label','alpha','sentence']]\n",
    "print(df)\n",
    "\n",
    "\"\"\"Retrieving the positive and negative indexes\"\"\"\n",
    "neg_index = [k for k in range(len(y)) if y[k]==0]\n",
    "pos_index = [k for k in range(len(y)) if y[k]==1]\n",
    "\n",
    "\"\"\"Shuffling both the positive and negative indexes\"\"\"\n",
    "np.random.seed(seed=0)\n",
    "np.random.shuffle(neg_index)\n",
    "np.random.shuffle(pos_index)\n",
    "\n",
    "\"\"\"Computing train and test index sets for the chosen number of folds\"\"\"\n",
    "cv = 10\n",
    "\n",
    "s = len(neg_index)//cv\n",
    "neg_index_list = [neg_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "neg_index_list.append(neg_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in neg_index_list])==len(neg_index)) # Check on negative index completion\n",
    "\n",
    "s = len(pos_index)//cv\n",
    "pos_index_list = [pos_index[k*s:(k+1)*s] for k in range(cv-1)]\n",
    "pos_index_list.append(pos_index[(cv-1)*s:])\n",
    "assert(np.sum([len(e) for e in pos_index_list])==len(pos_index))# Check on positive index completion\n",
    "\n",
    "y_tests = []\n",
    "\n",
    "for k in tqdm(range(cv)):\n",
    "    \"\"\"Splitting the data into train and test\"\"\"\n",
    "    print('{}-th fold'.format(k+1))\n",
    "    print('Splitting the data')\n",
    "    neg_test = neg_index_list[k]\n",
    "    pos_test = pos_index_list[k]\n",
    "    neg_train = list(set(neg_index).difference(neg_index_list[k]))\n",
    "    pos_train = list(set(pos_index).difference(pos_index_list[k]))\n",
    "    \n",
    "    pos_dev = pos_train[-1:]\n",
    "    neg_dev = neg_train[-1:]\n",
    "    pos_train = pos_train[:-1]\n",
    "    neg_train = neg_train[:-1]\n",
    "    \n",
    "    \"\"\"Splitting the data frames and saving to BERT format\"\"\"\n",
    "    list_train = pos_train + neg_train\n",
    "    list_dev = pos_dev + neg_dev\n",
    "    list_test = pos_test + neg_test\n",
    "\n",
    "    np.random.shuffle(list_train)\n",
    "    np.random.shuffle(list_dev)\n",
    "    np.random.shuffle(list_test)\n",
    "    \n",
    "    train_df = df.iloc[list_train]\n",
    "    dev_df = df.iloc[list_dev]\n",
    "    test_df = df.iloc[list_test]\n",
    "    y_tests.append(list(test_df.label))\n",
    "    print(len(y_tests[-1]))\n",
    "    \n",
    "    \"\"\"Making the directory to save the data if it doesn't exist\"\"\"\n",
    "    if not os.path.exists('./bert_ba/data_ba_'+str(k+1)):\n",
    "        os.mkdir('./bert_ba/data_ba_'+str(k+1))\n",
    "    \n",
    "    train_df.to_csv('./bert_ba/data_ba_{}/train.tsv'.format(str(k+1)), sep='\\t', index=False, header=False)\n",
    "    dev_df.to_csv('./bert_ba/data_ba_{}/dev.tsv'.format(str(k+1)), sep='\\t', index=False, header=False)\n",
    "    test_df[['id','sentence']].to_csv('./bert_ba/data_ba_{}/test.tsv'.format(str(k+1)), sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924fdaa3585b493986e5377abf1cb52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qrg-researchlab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/qrg-researchlab/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training and harvesting performance metrics\"\"\"\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "os.chdir(\"./bert_ba\")\n",
    "precs = []\n",
    "recs = []\n",
    "fs = []\n",
    "aucs = []\n",
    "for k in tqdm(range(cv)):\n",
    "    \"\"\"Instruction to train, evaluate, and predict results on test data\"\"\"\n",
    "    os.system(\"python run_classifier.py --task_name=cola --do_train=true --do_eval=true --do-predict=true --data_dir=./data_ba_{}/ --vocab_file=./cased_L-12_H-768_A-12/vocab.txt --bert_config_file=./cased_L-12_H-768_A-12/bert_config.json --init_checkpoint=./cased_L-12_H-768_A-12/bert_model.ckpt --max_seq_length=128 --train_batch_size=32 --learning_rate=2e-5 --num_train_epochs=10.0 --output_dir=./bert_output/ --do_lower_case=False\".format(str(k+1)))\n",
    "\n",
    "    test_res = pd.read_csv('./bert_output/test_results.tsv',sep='\\t', header=None)\n",
    "    test_res = list(test_res[1])\n",
    "    test_pred = [int(y>=0.5) for y in test_res]\n",
    "\n",
    "    y_test = y_tests[k]\n",
    "\n",
    "    precision = precision_score(y_test, test_pred)\n",
    "    recall = recall_score(y_test, test_pred)\n",
    "    f1_ = f1_score(y_test, test_pred)\n",
    "    roc_auc = roc_auc_score(y_test, test_res)\n",
    "    \n",
    "    precs.append(precision)\n",
    "    recs.append(recall)\n",
    "    fs.append(f1_)\n",
    "    aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.0+-\\0.0\n",
      "Recall : 0.0+-0.0\n",
      "F1 score : 0.0+-0.0\n",
      "ROC AUC : 0.6703769354446103+-0.027284518662572806\n"
     ]
    }
   ],
   "source": [
    "print('Precision : {}+-\\{}\\nRecall : {}+-{}\\nF1 score : {}+-{}\\nROC AUC : {}+-{}'.format(np.mean(precs),np.std(precs),\n",
    "                                                                                         np.mean(recs),np.std(recs),\n",
    "                                                                                         np.mean(fs),np.std(fs),\n",
    "                                                                                         np.mean(aucs),np.std(aucs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
